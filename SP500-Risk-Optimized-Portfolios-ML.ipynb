{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> <font color= 'blue'> S&P 500 Risk Optimizations Forecast </font> \n",
    "<div align=\"right\">\n",
    "\n",
    "[![S&P500-Optimizations-Forecast](https://img.shields.io/badge/EstebanMqz-README_>_S&P500_Risk_Optimizations_Forecast-black?style=square&logo=github&logoColor=black)](https://github.com/EstebanMqz/SP500-Risk-Optimizations-Forecast)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'blue'> Abstract: <font>\n",
    "\n",
    "<font color= 'black'> \n",
    "Time series modelling is a powerful forecast tool and the stock market tends to be an interesting example because statistical estimators are of special interest.<br> \n",
    "They are used for general prediction purposes and to make decision-making processes more efficient.<br>\n",
    "The industries where it can be applied are numerous, but the most common are the following:<br>\n",
    "\n",
    "- Government\n",
    "- Banking\n",
    "- Insurance\n",
    "- Energy\n",
    "- Healthcare\n",
    "- Telecommunications\n",
    "- Retail\n",
    "- Education"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= 'blue'> Description: <font>\n",
    "\n",
    "<font color= 'black'>\n",
    "\n",
    "Since Covid, data has changed in most industries with few exceptions and the markets are just another example.<br>\n",
    "\n",
    "With this in mind, the present repository automates tasks that deliver a full understanding of the market since and until the user *(you)* execution's date. <br>\n",
    "Furthermore, it generates a variety of optimizations whose purpose is to forecast the mentioned period while being able to incorporate newly generated data with the usage of the snippets provided by the scripts, which are executed by:&nbsp; [![S&P500-Optimizations-Forecast](https://img.shields.io/badge/Notebook-Run>All-black?style=square&logo=github&logoColor=black)](https://github.com/EstebanMqz/SP500-Risk-Optimizations-Forecast/blob/main/SP500-Risk-Optimized-Portfolios-ML.ipynb) <br>\n",
    "\n",
    "\n",
    "<left>\n",
    "\n",
    "##### <font color= 'blue'> Work Contact: <font>\n",
    "\n",
    "[![Website](https://img.shields.io/badge/Website-ffffff?style=square&logo=opera&logoColor=red)](https://estebanmqz.com) [![LinkedIn](https://img.shields.io/badge/LinkedIn-041a80?style=square&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/esteban-m65381722210212839/) [![Portfolio](https://img.shields.io/badge/Github-Portfolio-010b38?style=square&logo=github&logoColor=black)](https://estebanmqz.github.io/Portfolio/) [![E-mail](https://img.shields.io/badge/Business-Mail-052ce6?style=square&logo=mail&logoColor=white)](mailto:esteban@esteban.com)\n",
    "<br>\n",
    "\n",
    "![GitHub Logo](https://github.com/EstebanMqz.png?size=50) [![Github](https://img.shields.io/badge/Github-000000?style=square&logo=github&logoColor=white)](https://github.com/EstebanMqz) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "##### <font color= 'blue'> Table of Contents: </font>\n",
    "\n",
    "It is divided in the folllowing sections:\n",
    "\n",
    "0. *Requirements*:\n",
    "\n",
    "1. *Data Extraction and Exploration*: \n",
    "    + $x_i\\in [x_1,x_{500}] \\hookrightarrow S\\&P500$<br><br>\n",
    "\n",
    "2. *Descriptive Statistics $\\&$ Analytics*: \n",
    "    + $x_i\\in [x_1,x_{500}] \\hookrightarrow S\\&P500$<br>\n",
    "    + $x_{j\\neq i}\\in [x_1,x_{25}]_{{R_{Sortino_{+_{25}}}}} \\subset x_i$ <br><br>\n",
    "\n",
    "3. *Optimizations*:\n",
    "    + ${max}_{\\vec{w_{j\\neq{i}}}} R_{Sortino_{P}} \\models$ \n",
    "    $\\begin{Bmatrix} {max}_{\\vec{w_{j}}} R_{Sharpe_{P}} \\\\ {min}_{\\vec{w_{j}}} R_{\\sigma^2_{P}} \\\\ {max}_{\\vec{w_{j}}} R_{Calmar_{P}} \\\\ {max}_{\\vec{w_{j}}} R_{Burke{P}} \\\\ {max}_{\\vec{w_{j}}} R_{Traynor_{P}} \\\\ {max}_{\\vec{w_{j}}} R_{Jensen_{P}} \\\n",
    "    \\end{Bmatrix}$\n",
    "    $\\forall$  $x_{j\\neq i}\\in [x_1,x_{25}]_{{R_{Sortino_{+_{25}}}}}$ \n",
    "4. *Simulations*: \n",
    "$$ x_i \\sim X_i \\hookrightarrow {max}_{\\vec{w_{j\\neq{i}}}} R_{Sortino_{P}}$$\n",
    "\n",
    "5. *Forecast*: \n",
    "    + $X_{(t_1+t_2+..+t_n)} \\hookrightarrow {max}_{\\vec{w_{j\\neq{i}}}} R_{Sortino_{P}}$<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= 'blue'> Methodology: </font>\n",
    "\n",
    "<font color= 'black'>\n",
    "\n",
    "Efficient Data Extraction techniques are made for its cleaning and Exploration followed by Descriptive Statistics $\\forall x_i\\in [x_1,x_{500}] \\hookrightarrow$ S&P 500 that make a storytell out of themselves as well as what and how it has happened. \n",
    "\n",
    "*This is made in addition to theoretical demonstrations and experimental comparisons that opt for the use of transformed data.* <br>\n",
    "\n",
    "Moreover, estimators and statistical measures are modelled and they incorporate common periodicity resampling periods, <br>\n",
    "as well as some of the tools displayed on this `README.md`. </br>\n",
    "\n",
    "As result, the following optimizations are made to subsequently generate simulations with what would have been its past behavior, <br>\n",
    "concluding with the optimization's forecast out of simulated data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Optimizations:\n",
    "\n",
    "$$\\bigg[{max}_{\\vec{w_{j\\neq{i}}}} R_{Sortino_{P}} \\models {max|min}_{\\vec{w_{j\\neq{i}}}} R_{k}\\bigg] \\forall x_{j\\neq i}\\in [x_1,x_{25}]_{{R_{Sortino_{+_{25}}}}}$$\n",
    "\n",
    "\n",
    "Simulations:\n",
    "\n",
    "$$\\sum_{j\\neq{i}}^{n} x_i \\sim X_i \\hookrightarrow {max}_{\\vec{w_{j\\neq{i}}}} R_{Sortino_{P}}$$\n",
    "\n",
    "Time series forecast:\n",
    "\n",
    "$$X_{t_1+t_2+...+t_n} \\hookrightarrow {max}_{\\vec{w_{j\\neq{i}}}} R_{Sortino_{P}}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'blue'> 1. Requirements: <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.py', 'functions.py', 'visualizations.py']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "mod = [__import__(name[:-3]) for name in glob.glob('*.py')]\n",
    "glob.glob('*.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'> Project Creators: <span> <br>\n",
    "\n",
    "<font color= 'black'> \n",
    "\n",
    "Create `requirements.txt` file:\n",
    "\n",
    "<span style='color:teal'> [fn.get_requirements](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/functions.py): <span>\n",
    "\n",
    "<span style='color:gray'> *Skip to installation if you are not interested in contributing to the project.* <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -- -------------------------------------------------------------------------------------- -- # \n",
      "# -- project: S&P500-Risk-Optimized-Portfolios-PostCovid-ML                                 -- # \n",
      "# -- script: requirements.txt: txt file to download Python modules for execution            -- # \n",
      "# -- author: EstebanMqz                                                                     -- # \n",
      "# -- license: CC BY 3.0                                                                     -- # \n",
      "# -- repository: SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/requirements.txt    -- #                                  \n",
      "# -- -------------------------------------------------------------------------------------- -- # \n",
      "\n",
      "\n",
      "fitter >= 1.2.3\n",
      "matplotlib >= 3.5.3\n",
      "numpy >= 1.24.3\n",
      "pandas >= 1.4.4\n",
      "plotly >= 5.6.0\n",
      "scikit_learn >= 1.2.2\n",
      "scipy >= 1.7.3\n",
      "seaborn >= 0.11.2\n",
      "tabulate >= 0.8.9\n",
      "yahoofinancials >= 1.6\n",
      "jupyter >= 1.0.0 \n",
      "ipython >= 8.10.0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in ./requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!pipreqs --encoding utf-8 \"./\" --force\n",
    "\n",
    "docstring = \"\"\"# -- -------------------------------------------------------------------------------------- -- # \n",
    "# -- project: S&P500-Risk-Optimized-Portfolios-PostCovid-ML                                 -- # \n",
    "# -- script: requirements.txt: txt file to download Python modules for execution            -- # \n",
    "# -- author: EstebanMqz                                                                     -- # \n",
    "# -- license: CC BY 3.0                                                                     -- # \n",
    "# -- repository: SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/requirements.txt    -- #                                  \n",
    "# -- -------------------------------------------------------------------------------------- -- # \n",
    "\\n\n",
    "\"\"\"\n",
    "mod[1].get_requirements(docstring)\n",
    "\n",
    "with open(glob.glob('*.txt')[0], 'r') as file: print(file.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green'> Project Users: <span>\n",
    "\n",
    "<font color= 'black'> \n",
    "\n",
    "Install packages in created [`requirements.txt`](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/requirements.txt) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'blue'> 1.1 Load Libraries & Modules: <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, pipreqs, sys, warnings\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None\n",
    "              ,\"display.max_colwidth\", None, \"display.width\", None)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go \n",
    "import plotly.express as px\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn import metrics\n",
    "\n",
    "from statsmodels.tsa.stattools import pacf \n",
    "from statsmodels.tsa.stattools import acf\n",
    "import statsmodels.api as sm \n",
    "\n",
    "\n",
    "from yahoofinancials import YahooFinancials \n",
    "from tabulate import tabulate\n",
    "import IPython.display as d\n",
    "import IPython.core.display\n",
    "\n",
    "import ast\n",
    "from io import StringIO\n",
    "from fitter import Fitter, get_common_distributions, get_distributions \n",
    "import logging\n",
    "\n",
    "import datetime \n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### <font color= 'blue'> 2. Data Extraction and Exploration: <font>\n",
    "\n",
    "#### <font color= 'blue'> 2.1 Data Extraction: <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "In this section $x_i\\in [x_1,x_{500}] \\hookrightarrow S\\&P500$ quotes are fetched:\n",
    "\n",
    "<span style='color:gray'> *Fetching a lot of data from Yahoo Finance by batches is required to avoid host disruptions (other sources could be used).* <br>\n",
    "In this case, the batches include 50 tickers each from the S&P 500 index. <font>\n",
    "\n",
    "<span style='color:teal'> [fn.SP500_tickers](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/functions.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>FTSE_100</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>III.L</td>\n",
       "      <td>ABDN.L</td>\n",
       "      <td>ADM.L</td>\n",
       "      <td>AAF.L</td>\n",
       "      <td>AAL.L</td>\n",
       "      <td>ANTO.L</td>\n",
       "      <td>AHT.L</td>\n",
       "      <td>ABF.L</td>\n",
       "      <td>AZN.L</td>\n",
       "      <td>AUTO.L</td>\n",
       "      <td>AV.L</td>\n",
       "      <td>BME.L</td>\n",
       "      <td>BA.L</td>\n",
       "      <td>BARC.L</td>\n",
       "      <td>BDEV.L</td>\n",
       "      <td>BEZ.L</td>\n",
       "      <td>BKG.L</td>\n",
       "      <td>BP.L</td>\n",
       "      <td>BATS.L</td>\n",
       "      <td>BLND.L</td>\n",
       "      <td>BT-A.L</td>\n",
       "      <td>BNZL.L</td>\n",
       "      <td>BRBY.L</td>\n",
       "      <td>CNA.L</td>\n",
       "      <td>CCH.L</td>\n",
       "      <td>CPG.L</td>\n",
       "      <td>CTEC.L</td>\n",
       "      <td>CRH.L</td>\n",
       "      <td>CRDA.L</td>\n",
       "      <td>DCC.L</td>\n",
       "      <td>DGE.L</td>\n",
       "      <td>EDV.L</td>\n",
       "      <td>ENT.L</td>\n",
       "      <td>EXPN.L</td>\n",
       "      <td>FCIT.L</td>\n",
       "      <td>FLTR.L</td>\n",
       "      <td>FRAS.L</td>\n",
       "      <td>FRES.L</td>\n",
       "      <td>GLEN.L</td>\n",
       "      <td>GSK.L</td>\n",
       "      <td>HLN.L</td>\n",
       "      <td>HLMA.L</td>\n",
       "      <td>HL.L</td>\n",
       "      <td>HSX.L</td>\n",
       "      <td>HSBA.L</td>\n",
       "      <td>IHG.L</td>\n",
       "      <td>IMB.L</td>\n",
       "      <td>INF.L</td>\n",
       "      <td>IAG.L</td>\n",
       "      <td>ITRK.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JD.L</td>\n",
       "      <td>JMAT.L</td>\n",
       "      <td>KGF.L</td>\n",
       "      <td>LAND.L</td>\n",
       "      <td>LGEN.L</td>\n",
       "      <td>LLOY.L</td>\n",
       "      <td>LSEG.L</td>\n",
       "      <td>MNG.L</td>\n",
       "      <td>MRO.L</td>\n",
       "      <td>MNDI.L</td>\n",
       "      <td>NG.L</td>\n",
       "      <td>NWG.L</td>\n",
       "      <td>NXT.L</td>\n",
       "      <td>OCDO.L</td>\n",
       "      <td>PSON.L</td>\n",
       "      <td>PSH.L</td>\n",
       "      <td>PSN.L</td>\n",
       "      <td>PHNX.L</td>\n",
       "      <td>PRU.L</td>\n",
       "      <td>RKT.L</td>\n",
       "      <td>REL.L</td>\n",
       "      <td>RTO.L</td>\n",
       "      <td>RMV.L</td>\n",
       "      <td>RIO.L</td>\n",
       "      <td>RR.L</td>\n",
       "      <td>RS1.L</td>\n",
       "      <td>SGE.L</td>\n",
       "      <td>SBRY.L</td>\n",
       "      <td>SDR.L</td>\n",
       "      <td>SMT.L</td>\n",
       "      <td>SGRO.L</td>\n",
       "      <td>SVT.L</td>\n",
       "      <td>SHEL.L</td>\n",
       "      <td>SMDS.L</td>\n",
       "      <td>SMIN.L</td>\n",
       "      <td>SN.L</td>\n",
       "      <td>SKG.L</td>\n",
       "      <td>SPX.L</td>\n",
       "      <td>SSE.L</td>\n",
       "      <td>STAN.L</td>\n",
       "      <td>STJ.L</td>\n",
       "      <td>TW.L</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>ULVR.L</td>\n",
       "      <td>UU.L</td>\n",
       "      <td>UTG.L</td>\n",
       "      <td>VOD.L</td>\n",
       "      <td>WEIR.L</td>\n",
       "      <td>WTB.L</td>\n",
       "      <td>WPP.L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "FTSE_100     0       1      2       3       4       5       6      7      8   \\\n",
       "0         III.L  ABDN.L  ADM.L   AAF.L   AAL.L  ANTO.L   AHT.L  ABF.L  AZN.L   \n",
       "1          JD.L  JMAT.L  KGF.L  LAND.L  LGEN.L  LLOY.L  LSEG.L  MNG.L  MRO.L   \n",
       "\n",
       "FTSE_100      9     10     11     12      13      14     15     16      17  \\\n",
       "0         AUTO.L  AV.L  BME.L   BA.L  BARC.L  BDEV.L  BEZ.L  BKG.L    BP.L   \n",
       "1         MNDI.L  NG.L  NWG.L  NXT.L  OCDO.L  PSON.L  PSH.L  PSN.L  PHNX.L   \n",
       "\n",
       "FTSE_100      18      19      20      21      22     23     24     25      26  \\\n",
       "0         BATS.L  BLND.L  BT-A.L  BNZL.L  BRBY.L  CNA.L  CCH.L  CPG.L  CTEC.L   \n",
       "1          PRU.L   RKT.L   REL.L   RTO.L   RMV.L  RIO.L   RR.L  RS1.L   SGE.L   \n",
       "\n",
       "FTSE_100      27      28     29      30     31      32      33      34  \\\n",
       "0          CRH.L  CRDA.L  DCC.L   DGE.L  EDV.L   ENT.L  EXPN.L  FCIT.L   \n",
       "1         SBRY.L   SDR.L  SMT.L  SGRO.L  SVT.L  SHEL.L  SMDS.L  SMIN.L   \n",
       "\n",
       "FTSE_100      35      36      37      38      39     40      41      42  \\\n",
       "0         FLTR.L  FRAS.L  FRES.L  GLEN.L   GSK.L  HLN.L  HLMA.L    HL.L   \n",
       "1           SN.L   SKG.L   SPX.L   SSE.L  STAN.L  STJ.L    TW.L  TSCO.L   \n",
       "\n",
       "FTSE_100      43      44     45     46      47     48      49  \n",
       "0          HSX.L  HSBA.L  IHG.L  IMB.L   INF.L  IAG.L  ITRK.L  \n",
       "1         ULVR.L    UU.L  UTG.L  VOD.L  WEIR.L  WTB.L   WPP.L  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def fetch_index(batches):\n",
    "    \"\"\"\n",
    "    Function to fetch symbols as lists of lists with n batches from an index as input.\n",
    "    Note: Undivisible batches are rounded automatically to fetch all symbols from selected index. \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    batches : int\n",
    "             N symbols fetched as a list of lists.   \n",
    "    Returns:\n",
    "    -------\n",
    "        index_symbols = List of lists (batches) that contains symbols as strings to be passed to an OHLCV fetch function.\n",
    "    \"\"\"\n",
    "    index = input(\"Choose an index to fetch symbols from as: SP_500, Dow_30, Nasdaq_100, Russell_1000, FTSE_100, IPC_35, DAX_40, IBEX_35, CAC_40, EURSTOXX_50, FTSEMIB_40, HANGSENG_73, OMXC_25, SMI_20\")  \n",
    "    index = index.upper()\n",
    "    \n",
    "    if index == \"SP_500\":\n",
    "       index_html = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "       column = \"Symbol\" \n",
    "\n",
    "    elif index == \"Dow_30\":\n",
    "       index_html = pd.read_html(\"https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average\")\n",
    "       column = \"Symbol\"\n",
    "\n",
    "    elif index == \"Nasdaq_100\":\n",
    "       index_html = pd.read_html(\"https://en.wikipedia.org/wiki/NASDAQ-100\")\n",
    "       column = \"Ticker\"\n",
    "\n",
    "    elif index == \"Russell_1000\":\n",
    "         index_html = pd.read_html(\"https://en.wikipedia.org/wiki/Russell_1000_Index\")\n",
    "         column = \"Ticker\"\n",
    "\n",
    "    elif index == \"FTSE_100\":\n",
    "       index_html = pd.read_html(\"https://en.wikipedia.org/wiki/FTSE_100_Index\")\n",
    "       column = \"Ticker\"\n",
    "\n",
    "    elif index == \"IPC_35\":\n",
    "       index_html = pd.read_html(\"https://en.wikipedia.org/wiki/Indice_de_Precios_y_Cotizaciones\")\n",
    "       column = \"Symbol\"\n",
    "\n",
    "    elif index == \"DAX_40\":\n",
    "       index_html = pd.read_html(\"https://en.wikipedia.org/wiki/DAX\")\n",
    "       column = \"Ticker\"\n",
    "\n",
    "    elif index == \"IBEX_35\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/IBEX_35\")\n",
    "        column = \"Ticker\"\n",
    "\n",
    "    elif index == \"CAC_40\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/CAC_40\")\n",
    "        column = \"Ticker\"\n",
    "\n",
    "    elif index == \"EUROSTOXX_50\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/EURO_STOXX_50\")\n",
    "        column = \"Ticker\"\n",
    "\n",
    "    elif index == \"FTSEMIB_40\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/FTSE_MIB\")\n",
    "        column = \"Ticker\"\n",
    "\n",
    "    elif index == \"HANGSENG_73\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/Hang_Seng_Index\")\n",
    "        column = \"Ticker\"\n",
    "\n",
    "    elif index == \"OMXC_25\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/OMX_Copenhagen_20\")\n",
    "        column = \"Ticker Symbol\"\n",
    "\n",
    "    elif index == \"SMI_20\":\n",
    "        index_html = pd.read_html(\"https://en.wikipedia.org/wiki/Swiss_Market_Index\")\n",
    "        column = \"Ticker\"\n",
    "\n",
    "    \n",
    "        return \"Error: No index found\"\n",
    "\n",
    "    i = 0\n",
    "    while i < len(index_html):\n",
    "        try:\n",
    "            list = index_html[i][column].values.tolist() \n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    list = [[x.replace(\".\", \"-\") for x in list[x:x+batches]] for x in range(0, len(list), batches)]\n",
    "\n",
    "    if index == \"FTSE_100\": \n",
    "        list = [[x + \".L\" for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list)\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "\n",
    "    if index == \"IPC_35\":\n",
    "        list = [[x + \".MX\" for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list)\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "\n",
    "    if index == \"IBEX_35\":\n",
    "        list = [[x + \".MC\" for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list)\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "    \n",
    "    if index == \"CAC_40\":\n",
    "        list = [[x.replace(\"-\", \".\") for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list)\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "\n",
    "    if index == \"EUROSTOXX_50\":\n",
    "        list = [[x.replace(\"-\", \".\") for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list)\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "\n",
    "    if index == \"FTSEMIB_40\":\n",
    "        list = [[x.replace(\"-\", \".\") for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list)\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "\n",
    "    if index == \"HANGSENG_73\":\n",
    "        list = [item for sublist in list for item in sublist]\n",
    "        list = [re.findall(r'\\d+', x) for x in list]\n",
    "        list = [[x.zfill(4) for x in list[i]] for i in range(len(list))]\n",
    "        list = [[x + \".HK\" for x in list[i]] for i in range(len(list))]\n",
    "        df = pd.DataFrame(list).T\n",
    "        df.rename_axis(index, axis=1, inplace=True)\n",
    "\n",
    "    if i > len(index_html) or list == []:\n",
    "        return \"Error: No symbols found.\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "DAX_40 = fetch_index(50)\n",
    "DAX_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = fn.SP500_tickers(50)\n",
    "tickers[0][:5], tickers[-1][0:5], sum([len(i) for i in tickers])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:gray'> *Note: Skip to 1.1.2 if you prefer using .csv creation date.* <font> &nbsp; "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "$6_Y$ $x_i\\in [x_1,x_{500}] \\hookrightarrow S\\&P500$ Adj. closes are fetched *(5min)* :<br>\n",
    "\n",
    "<span style='color:teal'> [dt.get_historical_price_data](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/data.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_Assets_f = pd.concat([dt.get_historical_price_data(tickers[i][j], 6) \n",
    "                         for i in range(0, len(tickers)) for j in range(0, len(tickers[i]))], axis=1)\n",
    "SP_Assets_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_Assets_f.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Adj. closes for $S\\&P500$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_f = dt.get_historical_price_data('^GSPC', 6)\n",
    "SP_f = SP_f[SP_f.index.isin(SP_Assets_f.index)]\n",
    "SP_f.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Fetched data is saved in [*Data*](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/tree/main/Data) subdirectory:<br>\n",
    "+ `Assets_SP500.csv`\n",
    "+ `SP500_index.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_Assets_f.to_csv(\"Data/Assets_SP500.csv\")   \n",
    "SP_f.to_csv(\"Data/SP500.csv\")\n",
    "SP_f = pd.read_csv(\"Data/SP500.csv\", index_col=0)\n",
    "SP_Assets_f = pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Fetched $x_i$ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_Assets_f.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_Assets_f.tail(8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color= 'black'> \n",
    "\n",
    "To skip data fetching if needed, a data reader is made available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_r = pd.read_csv(\"Data/SP500.csv\", index_col=0)\n",
    "SP_Assets_r = pd.read_csv(\"Data/Assets_SP500.csv\", index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= 'blue'> 2.2 Data Exploration <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Defining Returns:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Accumulated Simple and Log Returns:\n",
    "\n",
    "+ *Multiplicative - Additive*: <br>\n",
    "\n",
    "$r_t = \\bigg(\\frac{P_{t+1}}{P_{t}}-1\\bigg)$\n",
    "\n",
    "Simple Returns $R_t$ are multiplicative because the following is true to calculate compounded interests\n",
    "\n",
    "$$1 + \\sum_{t=1}^{n} r_t = 1+r_1+r_2+...+r_n \\neq \\prod_{t=1}^{n} (1+r_t) = \\prod_{t=1}^{n}\\bigg(1+\\frac{P_{t+1}}{P_{t}-1}\\bigg)$$\n",
    "\n",
    "$\\therefore$ Accumulated $R_t$ is only represented from the exponential law: $\\bigg(1+\\frac{P_{t+1}}{P_{t}}\\bigg)^n$ as *multiplicative*:  $$\\sum_{t=1}^{n} R_t = \\prod_{t=1}^{n}(1+r_t)$$\n",
    "\n",
    "On the other hand, Accumulated $r_t$ is only represented from the exponential law: $\\mathrm{e}^{{P_t} \\times {P_{{t+1}}}}= \\mathrm{e}^{{P_t} + {P_{{t+1}}}}$ as *additive*:\n",
    "\n",
    "$$\\sum_{t=1}^{n} r_t = \\bigg[{\\mathrm{e}^{\\sum_{t=1}^{n} ln (1+r_t) }} \\bigg]$$\n",
    "\n",
    "As conclusion:\n",
    "\n",
    "$$\\prod_{t=1}^{n}(1+r_t) \\implies \\bigg[{\\mathrm{e}^{\\sum_{t=1}^{n} ln (1+r_t) }} \\bigg]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'white'> \n",
    "\n",
    "#### Simple $R_t$ and $ln(1+ r_t)$ Returns:\n",
    "\n",
    "Their Characteristics involve respectively:\n",
    "+ *Multiplicative - Additive*:<br>\n",
    "Simple Returns $R_t$ are multiplicative. Whereas  of what it was previously as it was previously demonstrated.\n",
    "\n",
    "\n",
    "+ *Not Symmetric - Symmetric*:<br>\n",
    "$R_t$ distribution can have $\\pm$ skew which makes the $Mo$, median and $\\mu$ not centered in $f(x)$.<br>\n",
    "$ln(r_t)$ distribution is symmetrical which makes the $Mo$, median and $\\mu$ centered in $f(x)$.\n",
    "\n",
    "+ *Not Stationary - Stationary*:<br>\n",
    "$R_t$ has a trend so they are not stationary, nor *i.i.d* and therefore correlated. $ln(1+ r_t)$ are stationary, therefore *i.i.d* and not correlated.\n",
    "\n",
    "+ *Not Independent - Independent*: <br>\n",
    "$R_t$ are not *i.i.d* because they are non stationary, they do have a trend so they are correlated and ultimately multiplicative.<br>\n",
    "On the other hand $ln(r_t)$ are *i.i.d* because they are stationary, they do not have a trend so they aren't correlated, which makes them additive.\n",
    "\n",
    "Simple Returns $R_t$ are correlated (not i.i.d) so they shouldn't be used to generate continous random variable simulations. <br>\n",
    "On the other hand, Log Returns are i.i.d because their additive nature makes not correlated, therefore they can be used to generate continous random variables.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Nevertheless, both Returns will be compared $\\forall$ $x_i\\in [x_1,x_{500}]$ $\\hookrightarrow$ $S\\&P500$ in Data Exploration.<br>\n",
    "And $\\forall$ $x_{i}\\in [x_1,x_{n=25}]$ $\\hookrightarrow$ ${max|min}_{\\vec{w_{j\\neq{i}}}} R_{k}$ Descriptive Statistics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "[Continous](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html) random variables distributions in Scipy for $ln(1+ r_t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = [d for d in dir(st) if isinstance(getattr(st, d), getattr(st, \"rv_continuous\"))]\n",
    "discrete = [d for d in dir(st) if isinstance(getattr(st, d), getattr(st, \"rv_discrete\"))]\n",
    "pd.DataFrame(continuous).rename(columns={0:\"Continuous\"}).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "[Discrete](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_discrete.html) random variables distributions in Scipy not considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(discrete).T.rename(index={0:\"Discrete\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "Required dates are shorter, they will be modified the rest of the project: \n",
    "<br><br>\n",
    "\n",
    "\n",
    "<font color= 'gray'> \n",
    "\n",
    "\n",
    "Start Date modified:<br>\n",
    "+ from $(2017-05-23)$ $\\to$ $(2020-03-02)$ <br> \n",
    "\n",
    "Resulting dates:\n",
    "+ from $(2020-03-02) \\to (2023-05-19)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Variables that will be used for the rest of the project are defined for the mentioned dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, best, r_jump, start, end = .00169, 25, 0.05, \"2020-03-02\", SP_Assets_r.tail(1).index[0]\n",
    "prices_start = SP_Assets_r.loc[start:end]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Symbols with missing values are located with a DQR:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:teal'>[`dt.DQR`](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/data.py)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQR_start = dt.DQR(prices_start).sort_values(by='Missing_Values', ascending=False)\n",
    "DQR_start.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_missing = (DQR_start[DQR_start['Missing_Values'] >= 1].index).values\n",
    "index_missing, index_missing.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "498 columns are left by removing missing values. Prices have a new shape defined by *(actual_cols = original_cols - missing_cols)*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_start = prices_start.drop(index_missing, axis=1)\n",
    "len(prices_start.T), sum([len(i) for i in tickers]), index_missing.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:teal'> [`dt.data_describe`](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/data.py)<br>\n",
    "\n",
    "+ <span style='color:teal'> [`fn.VaR`](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/functions.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'blue'> 2.2.1 Prices <font> \n",
    "\n",
    "<font color= 'black'>\n",
    "Statistical descriptions of the prices, sorted by their Total Change is shown for the period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_stats = dt.data_describe(prices_start, 'Prices', .00169, start, end)\n",
    "prices_stats = prices_stats.T.sort_values(by = 'Total_Change', ascending = False).T\n",
    "prices_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'white'> \n",
    "\n",
    "Simple Returns $x_i\\in [x_1,x_{500}] \\hookrightarrow S\\&P500$ are:<br>\n",
    "Not symmetric, they are skewed, they are not stationary and they are not i.i.d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats_Simple, Simple_ret = data_describe(prices_start, 'Simple', rf, start, end)[:2]\n",
    "Stats_Simple = Stats_Simple.T.sort_values(by = 'Yr_Return', ascending = False).T\n",
    "Stats_Simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'white'> \n",
    "\n",
    "Considering Quotes are sorted by Yr_Return, what the following chart shows is basically that even though there are quotes who were highly ranked in terms of Returns, not so much in terms of negative volatility, so people or firms could still have lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.distplot(.T.Yr_Return, bins=50, color = 'blue', label = '$R_t$')\n",
    "sns.kdeplot(Stats_Simple.T.Yr_Return, color = 'orange', linestyle=\"--\")\n",
    "sns.distplot(Stats_Simple.T.Yr_Return, bins=50, color = 'blue', label = '$R_t$')\n",
    "sns.kdeplot(Stats_Simple.T.Yr_Return, color = 'orange', linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col, df_index = Stats_Simple.T['Sortino'], (Stats_Simple.T['Sortino'].index)\n",
    "x_arange, y_arange = np.arange(0, Stats_Simple.T['Sortino'].index.shape[0], 10), np.arange(round(Stats_Simple.T['Sortino'].min(), 2), round(Stats_Simple.T['Sortino'].max(), 2), .10)\n",
    "title = (str(Stats_Simple.T['Sortino'].index.name) + \" Simple Sortino Ratio from \" + str(start) + \" to \" + str(end))\n",
    "x_label, y_label = \"Datasets $x_i$\", \"Sortino Ratio\"\n",
    "\n",
    "vs.cmap_bar(df_col, df_index, x_arange, y_arange, title, x_label, y_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "As it was stated, not all risks are bad, so in this case the biggest winners had the most uncertainty which caused by rapid fluctuations which ended in a positive way. Tesla's volatility was one of the highest as well as its sucess in the Top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col, df_index = Stats_Simple.T['Yr_Std'].head(50), (Stats_Simple.T['Yr_Std'].head(50).index)\n",
    "x_arange, y_arange = np.arange(0, Stats_Simple.T['Yr_Std'].head(50).index.shape[0], 1), np.arange(round(Stats_Simple.T['Yr_Std'].head(50).min(), 2), round(Stats_Simple.T['Yr_Std'].head(50).max(), 2), .05)\n",
    "title = (str(Stats_Simple.T['Yr_Std'].head(50).index.name) + \" best 50 $R_t$ with $\\sigma_{Yr}$ from\" + str(start) + \" to \" + str(end))\n",
    "x_label, y_label = \"Datasets $x_i$\", \"Std. Deviation Yrly.\"\n",
    "\n",
    "std_head = vs.cmap_bar(df_col, df_index, x_arange, y_arange, title, x_label, y_label)\n",
    "\n",
    "df_col, df_index = Stats_Simple.T['Yr_Std'].tail(50), (Stats_Simple.T['Yr_Std'].tail(50).index)\n",
    "x_arange, y_arange = np.arange(0, Stats_Simple.T['Yr_Std'].tail(50).index.shape[0], 1), np.arange(round(Stats_Simple.T['Yr_Std'].tail(50).min(), 2), round(Stats_Simple.T['Yr_Std'].tail(50).max(), 2), .05)\n",
    "title = (str(Stats_Simple.T['Yr_Std'].tail(50).index.name) + \" worst 50 $R_t$ with $\\sigma_{Yr}$ from\" + str(start) + \" to \" + str(end))\n",
    "x_label, y_label = \"Datasets $x_i$\", \"Std. Deviation Yrly.\"\n",
    "\n",
    "std_tail = vs.cmap_bar(df_col, df_index, x_arange, y_arange, title, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats_Log = data_describe(prices_start, 'Log_returns', .00169, start, end)[0]\n",
    "Stats_Log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:teal'> [`vs.cmap_bar`](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/visualizations.py)<br>\n",
    "\n",
    "<font color= 'white'> \n",
    "\n",
    "Total Price Changes $\\frac{P_{{(2023-05-19)}}}{P_{(2020-03-02)}} - 1$ &nbsp; $\\forall$ &nbsp; $x_i\\in [x_1,x_{500}] \\hookrightarrow S\\&P500$ Statistical Descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col, df_index = prices_stats.T['Total_Change'], (prices_stats.T['Total_Change'].index)\n",
    "x_arange, y_arange = np.arange(0, prices_stats.T['Total_Change'].index.shape[0], 10), np.arange(round(prices_stats.T['Total_Change'].min(), 2), round(prices_stats.T['Total_Change'].max(), 2), .25)\n",
    "title = (str(prices_stats.T['Total_Change'].index.name) + \" Total Change from \" + str(start) + \" to \" + str(end))\n",
    "x_label, y_label = \"Datasets $x_i$\", \"Total Price Change\"\n",
    "\n",
    "vs.cmap_bar(df_col, df_index, x_arange, y_arange, title, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.distplot(Stats_Simple.T.Yr_Return, bins=50, color = 'blue', label = '$R_t$')\n",
    "sns.kdeplot(Stats_Simple.T.Yr_Return, color = 'orange', linestyle=\"--\")\n",
    "sns.distplot(Stats_Simple.T.Yr_Return, bins=50, color = 'blue', label = '$R_t$')\n",
    "sns.kdeplot(Stats_Simple.T.Yr_Return, color = 'orange', linestyle=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple.T.Simple_skew.plot(kind=\"bar\", figsize=(20, 5), color=\"orange\", alpha=.5, label=\"Simple Skew\")\n",
    "Log.T.Logret_skew.plot(kind=\"bar\", figsize=(20, 5), color=\"yellow\", alpha=.5, label=\"Log Skew\")\n",
    "plt.xticks(rotation=0, fontsize=2)\n",
    "#Drop x ticks and make new ticks from 0 to 500 with a step of 10\n",
    "plt.xticks(np.arange(0, 500, 10))\n",
    "plt.xticks(fontsize=8)\n",
    "#x ticks rotation\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "plt.xlabel(\"Assets\")\n",
    "plt.ylabel(\"Skew\")\n",
    "plt.title(\"Simple Skew\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Simple.T.Simple_kurtosis.plot(kind=\"bar\", figsize=(20, 5), color=\"green\", alpha=.5, label=\"Simple Kurtosis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dist_KDE(dataframe1, dataframe2, dist_label1, dist_label2, x_ticks, y_ticks):\n",
    "    \"\"\"\n",
    "    Function to plot yearly returns distribution and kde with Yearly Simple & Log returns in index as dataframe with quotes in cols.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    Simple: dataframe\n",
    "        Dataframe with simple returns.\n",
    "    Log: dataframe\n",
    "        Dataframe with log returns.\n",
    "    color: str\n",
    "        Color for plot ticks, labels and title text\n",
    "    Returns:\n",
    "    -------\n",
    "    Plot with yearly returns.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    sns.distplot(dataframe1, bins=50, color = 'red', label = dist_label1)\n",
    "    sns.distplot(dataframe2, bins=50, color = 'blue', label = dist_label2)\n",
    "\n",
    "    sns.kdeplot(dataframe1, color = 'orange', linestyle=\"--\")\n",
    "    sns.kdeplot(dataframe2, color = 'teal', linestyle=\"--\")\n",
    "\n",
    "    plt.title(title,  fontsize=15)\n",
    "    plt.grid(color='gray', linestyle='--')\n",
    "    #plt.yticks(y_ticks)\n",
    "    plt.xticks(x_ticks, rotation=45, fontsize=9)\n",
    "    plt.xlabel(x_label, fontsize=15), plt.ylabel(y_label, fontsize=15)\n",
    "    #plt.margins(x=0, y=0)\n",
    "    #plt.tight_layout()\n",
    "    ax.xaxis.label.set_color('red'), ax.yaxis.label.set_color('blue')\n",
    "    ax.tick_params(axis='x', colors='white'), ax.tick_params(axis='y', colors='white')\n",
    "    plt.legend()\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "def Yearly_Returns(Simple, Log, color):\n",
    "    \"\"\"\n",
    "    Function to plot yearly returns distribution and kde with Yearly Simple & Log returns in index as dataframe with quotes in cols.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    Simple: dataframe\n",
    "        Dataframe with simple returns.\n",
    "    Log: dataframe\n",
    "        Dataframe with log returns.\n",
    "    color: str\n",
    "        Color for plot ticks, labels and title text\n",
    "    Returns:\n",
    "    -------\n",
    "    Plot with yearly returns.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    sns.distplot(Simple.T.Yr_Return, bins=50, color=\"red\", label=\"Yearly Simple $R_t$\")\n",
    "    sns.distplot(Log.T.Yr_Return, bins=50, color=\"blue\", label=\"Yearly Log $r_t$\")\n",
    "\n",
    "    sns.kdeplot(Simple.T.Yr_Return, color=\"orange\", linestyle=\"--\")\n",
    "    sns.kdeplot(Log.T.Yr_Return, color=\"teal\", linestyle=\"--\")\n",
    "\n",
    "    plt.title(\"$x_i\\in [x_1,x_{500}]$ in S&P500 Yearly Returns\", size=20).set_color(color)\n",
    "    plt.xticks(np.arange(round(min(Simple.T.Yr_Return), 1)*1.5, round(max(Simple.T.Yr_Return), 1)*1.5, 0.05))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Yearly Returns\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    ax.xaxis.label.set_color(color), ax.yaxis.label.set_color(color)\n",
    "    ax.tick_params(axis='x', colors=color), ax.tick_params(axis='y', colors=color)\n",
    "\n",
    "\n",
    "    plt.grid(color='gray', linestyle='--')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def Stationarity(x, y, n):\n",
    "    \"\"\"\n",
    "    Function that plots a time-series and its Trend, Seasonality and Residuals \n",
    "    returning the Augmented Dickey Fuller p-value for given n periods.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: DateTime values from economic index (col). #data_raw['DateTime']\n",
    "        y: Actual values from economic index (col). #data_raw['Actual']\n",
    "        n: Periods for decomposition (int).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lines+marker Series, Trend, Seasonality and Residuals plots in a didactic graph with plotly.\n",
    "    \"\"\"\n",
    "\n",
    "    decomposition = seasonal_decompose(y, period = n)\n",
    "\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    fig = make_subplots(rows = 4, cols = 1, shared_xaxes = False, \n",
    "                        subplot_titles = ('Actual', 'Trend', 'Seasonal', 'Residuals'),\n",
    "                        vertical_spacing = 0.15, row_width = [0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=y, mode='lines+markers', name='Actual',\n",
    "         line=dict(color='black'), marker=dict(symbol=2, color='black')))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=trend, mode='lines+markers', name='Trend',\n",
    "         line=dict(color='black'), marker=dict(symbol=2, color='blue')), row = 2, col = 1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=seasonal, mode='lines+markers', name='Seasonal',\n",
    "         line=dict(color='black'), marker=dict(symbol=2, color='green')), row = 3, col = 1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=residual, mode='lines+markers', name='Residuals',\n",
    "         line=dict(color='black'), marker=dict(symbol=2, color='gray')), row = 4, col = 1)\n",
    "\n",
    "    fig.show(),fig.show(\"png\")\n",
    "   \n",
    "    return \"p-value:\", adfuller(y)[1], \n",
    "\n",
    "\n",
    "def qq(index):\n",
    "    \"\"\"\n",
    "    Function that graphs a QQ-plot intended to model economic index Actual values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index: Actual values from economic index (col) \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        QQ-plot for given data.\n",
    "    \"\"\"\n",
    "    sm.qqplot(index, line= 'q', fit  = True)\n",
    "    pylab.show()    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= 'lightblue'> 2. Descriptive Statistics: <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Statistical descriptions are the foundation of the knowledge from data and valuable insights can be communicated.<br>\n",
    "In this case, statistical descriptions establish foundations that can analyze new data at any given time and evaluate for example<br>\n",
    "if it is more feasible due to reasons that aren't captured by data to include $\\vec{w_{i\\neq j}}$ or have $\\vec{w_{i}}$ adjusted and/or discarded from ${max|min}_{\\vec{w_i}} R_{j_+}$ \n",
    "\n",
    "For future references, fitted params. estimators $f(\\hat{X_i})$ will be obtained and their relative qualities assesed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:teal'> [`vs.selection_data`](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/visualizations.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "$x_i\\in [x_1 , x_{25}] \\hookrightarrow R_{Sortino_{+_{25}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(((Sortino.sort_values(by=\"sortino\", ascending=False).head(25).T).iloc[7:, :]).mean(axis=1)).rename(columns={0:\"Equiprob. xi mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices, r_log, summary_log = vs.selection_data(SP_Assets_r, \"Log\", rf, best, start, end)\n",
    "prices, r_simple, summary_simple = vs.selection_data(SP_Assets_r, \"Simple\", rf, best, start, end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Log Returns $r_t$ Data Selection from which optimizations will be performed are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.Markdown(tabulate(summary_log, headers='keys', tablefmt='pipe'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[vs.BoxHist](https://github.com/EstebanMqz/SP500-Risk-Optimized-Portfolios-PostCovid-ML/blob/main/visualizations.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoxHist(data, output, bins, color, label, title, start, end):\n",
    "    \"\"\"Boxplot and Histogram for selected output method for returns method for data, assuming equiprobable weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        Data to plot.\n",
    "    output: str\n",
    "        'prices' or 'log_returns' string to return its stats.\n",
    "    bins : int\n",
    "        Number of bins for histogram.\n",
    "    color : str\n",
    "        Color for plots.\n",
    "    x1_label : str\n",
    "        x1_label for boxplot.\n",
    "    x2_label : str\n",
    "        x2_label for histogram.\n",
    "    title : str\n",
    "        Title for both plots.\n",
    "    start : str\n",
    "        Start date for Stats calculations from dt.data_describe.\n",
    "    end : str\n",
    "        End date for Stats calculations from dt.data_describe.\n",
    "    Returns\n",
    "    -------\n",
    "    Boxplot and Histogram with Stats visualization \n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Boxplot and Histogram of Returns Method with its dt.describe_stats summary with equiprobable weights.\n",
    "    \"\"\"\n",
    "    plt.style.use(\"classic\")\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "    data.plot.box(ax=ax1, color=color, vert=False)\n",
    "    Box_Stats = pd.DataFrame(((dt.data_describe(data, output, .00169, start, end).sort_values(by=\"sortino\", \n",
    "    ascending=False).head(25).T).iloc[7:, :]).mean(axis=1)).rename(columns={0:\"Equiprob. xi mean\"})\n",
    "\n",
    "    plt.text(0.05, 0.05, data.describe().round(6).to_string(), transform=ax1.transAxes)\n",
    "\n",
    "    ax1.set_xlabel(label)\n",
    "    sns.histplot(data, bins=bins, kde=True, alpha=0.5, ax=ax2).legend().remove()\n",
    "    for patch in ax2.patches:\n",
    "        patch.set_facecolor(color)\n",
    "    ax2.set_yticklabels([\"{:.2f}%\".format(x/10000) for x in ax2.get_yticks()])\n",
    "    ax2.set_ylabel(\"Probability\")\n",
    "    ax2.set_xlabel(label)\n",
    "    fig.suptitle(str(label) + title, fontsize=18)\n",
    "    ax1.grid(color=\"gray\", linestyle=\"--\"), ax2.grid(color=\"lightgray\", linestyle=\"--\")\n",
    "    #Face color for plots\n",
    "    ax1.set_facecolor(\"lightgray\"), ax2.set_facecolor(\"lightgray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxHist(r_log.mean()*252, 30, 'blue', \"$\\mu_{Yr}{{r_{t}}(x_i)$\", \"$\\in [x_1,x_{500}]$ $\\hookrightarrow$ S&P500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoxHistTest(data, bins, color, label, title):\n",
    "    \"\"\"Boxplot and Histogram for given data\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        Data to plot.\n",
    "    bins : int\n",
    "        Number of bins for histogram.\n",
    "    color : str\n",
    "        Color for plots.\n",
    "    x1_label : str\n",
    "        x1_label for boxplot.\n",
    "    x2_label : str\n",
    "        x2_label for histogram.\n",
    "    title : str\n",
    "        Title for both plots.\n",
    "    Returns\n",
    "    -------\n",
    "    Boxplot and Histogram of data\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "    data.plot.box(ax=ax1, color=color, vert=False)\n",
    "    stats = pd.DataFrame(dt.data_describe(data).mean(axis=1).round(6)).iloc[3:].rename(columns={0:label}).dropna().to_string()\n",
    "    plt.text(0.05, 0.05, stats, transform=ax1.transAxes)\n",
    "    ax1.set_xlabel(label)\n",
    "    sns.histplot(data, bins=bins, kde=True, alpha=0.5, ax=ax2).legend().remove()\n",
    "    for patch in ax2.patches:\n",
    "        patch.set_facecolor(color)\n",
    "    ax2.set_yticklabels([\"{:.2f}%\".format(x/10000) for x in ax2.get_yticks()])\n",
    "    ax2.set_ylabel(\"Probability\")\n",
    "    ax2.set_xlabel(label)\n",
    "    fig.suptitle(str(label) + title, fontsize=18, fontweight=\"bold\")\n",
    "    ax1.grid(color=\"gray\", linestyle=\"--\"), ax2.grid(color=\"lightgray\", linestyle=\"--\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dt.data_describe(r_simple.sample(100000, replace=True)).mean(axis=1)).iloc[3:].rename(columns={0:\"(Rt)\"}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = pd.DataFrame(r_simple.mean(axis=1)).sample(100000, replace=True)\n",
    "Xi.sort_index(inplace=True)\n",
    "Xi = Xi.groupby(Xi.index).mean()\n",
    "Xi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.data_describe(Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxHistTest(r_simple.mean().to_frame(), 30, 'blue', \"$\\mu_{R_{t}}(x_i)$\", \" Simple Returns $X_i\\sim N({\\mu}_{R_t}, {\\sigma^2}_{R_t})$ in S&P500\")\n",
    "#vs.BoxHist(r_simple.var().to_frame().sample(100000, replace=True).rename(columns={0:\"(Rt)\"}), 20, 'blue', \"$\\sigma^2_{R_{t}}(X_i)$\", \" Simple Returns Variance Simulations $X_i\\in [X_1,X_{500}]$\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Log Returns $r_{t_n}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices, r_log, summary_log = vs.selection_data(SP_Assets_r, \"Log\", rf, best, start, execution_date)\n",
    "r_log.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "$\\therefore$ Random variables ${X_i\\sim N(\\mu_{r_{t}}, \\sigma^2_{r_{t}})}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.BoxHist(r_log.mean().to_frame().rename(columns={0:\"mu(rt)\"}), 20, '#0998eb', \"$\\mu_{r_{t}}(X_i)$\", \" Log Returns Mean Simulations$_{100k}$ $X_i\\in [X_1,X_{500}]$\")\n",
    "#vs.BoxHist(r_log.var().to_frame().sample(100000, replace=True).rename(columns={0:\"(Rt)\"}), 20, 'lightblue', \"$\\sigma^2_{R_{t}}(X_i)$\", \" Log Returns Variance Simulations $X_i\\in [X_1,X_{500}]$\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "The Simple Returns mean differ from Log Returns just enough for the model not to be modelled correctly.<br>\n",
    "Nevertheless, compounding effects among other factors make Log Returns best suitable for the model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'lightblue'> \n",
    "\n",
    "2.1.3 Cumulative $\\bold{_{R_{t}}(X_i)}$ $\\&$ Log $\\bold{\\mu_{r_{t}}(X_i)}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Simple Returns $R_{t}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_simple_acum = ((1+r_simple).cumprod()-1)\n",
    "r_simple_acum = r_simple_acum.T[(r_simple_acum.T >= -1) & (r_simple_acum.T <= 1)].T\n",
    "r_simple_acum = r_simple_acum.fillna(method='ffill')\n",
    "r_simple_acum.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "$\\therefore$ Random variables ${X_i\\sim N(\\mu_{R_{t}}, \\sigma^2_{R_{t}})}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.BoxHist(r_simple_acum.mean().sample(100000, replace=True).rename(index={0:\"Accum_mu(Rt)\"}), 30, '#d1423d', \"Accum. $\\mu_{R_{t}}(X_i)$\", \"Simple Returns Mean Simulations$_{100k}$ $X_i\\in [X_1,X_{500}]$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.BoxHist(r_simple_acum.var().sample(100000, replace=True).rename(index={0:\"Accum_s(Rt)\"}), 30, '#eb1c15', \"Accum. $\\sigma^2_{R_{t}}(X_i)$\", \"Simple Returns Variance Simulations$_{100k}$ $X_i\\in [X_1,X_{500}]$\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "Log Returns $r_{t_n}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_log_acum = ((1+r_log).cumprod()-1)\n",
    "r_log_acum.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "$\\therefore$ Random variables ${X_i\\sim N(\\mu_{R_{t}}, \\sigma^2_{R_{t}})}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.BoxHist(r_log_acum.mean().to_frame().sample(100000, replace=True).rename(columns={0:\"Accum_mu(rt)\"}), 20, '#0e7a04', \"$\\mu_{r_{t}}(X_i)$\", \" Log Returns Mean Simulations $X_i\\in [X_1,X_{500}]$\")\n",
    "#vs.BoxHist(r_log.var().to_frame().sample(100000, replace=True).rename(columns={0:\"(Rt)\"}), 20, 'green', \"$\\sigma^2_{R_{t}}(X_i)$\", \" Log Returns Variance Simulations $X_i\\in [X_1,X_{500}]$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outliers:\", len(r_log_acum.mean(axis=1)[abs(r_log_acum.mean(axis=1) - np.mean(r_log_acum.mean(axis=1))) < 2 * np.std(r_log_acum.mean(axis=1))].to_frame())/100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.BoxHist(r_log_acum.var().to_frame().sample(100000, replace=True).rename(columns={0:\"Accum_s(rt)\"}), 20, '#25c716', \"Accum. $\\sigma^2_{r_{t}}(X_i)$\", \" Log Returns Variance Simulations $X_i\\in [X_1,X_{500}]$\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Sharpe's Ratio measures the units of risk *($\\small \\sigma$)* per unit of excess returns over a risk-free rate *($\\small rf$)* :\n",
    "+ $R_{Sharpe} = \\frac{\\mu_i - {rf}}{\\sigma_i(r_t)}$.\n",
    "<br>\n",
    "\n",
    "Sortino's Ratio measures the units of negative risks *[$\\sigma_{i}\\small(r_{t\\leq 0})$]* per unit of excess returns over a risk-free rate *($\\small rf$)* :\n",
    "+ $R_{Sortino} = \\frac{\\mu_i - {rf}}{\\sigma_{i}(r_{t\\leq 0})}$ \n",
    "\n",
    "To avoid risks associated to negative returns, Data Selection $\\forall X_i\\in [X_1,X_{500}] \\rightarrow X_{P{_{R{max_{j}}}}}$ is based on $S\\&P500$ *Sortino's Ratio Top 25*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.retSLog_Selection(SP_Assets_r, rf, best, start, execution_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.Selection_R_SLog_Plot(SP_Assets_r, rf, best, start, execution_date, r_jump)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'blue'> <br> 2.2 Modelling $X_i$ <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stats(dataframe, Selection, r, P, percentiles, dist, title, color):\n",
    "    \"\"\"\n",
    "    Stats is a function that resamples data from a Selection performed over a dataframe.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataframe : dataframe\n",
    "        Dataframe from which the Selection is made, in order to acess Selection's original data.\n",
    "    Selection : list\n",
    "        Selection to Resample for given period(s) etc. basis whose period is longer than original data.\n",
    "    r : str\n",
    "        Type of return for the model: \"Simple\" (multiplicative) or \"Log\" (additive).\n",
    "    P : str\n",
    "        Period of Resample (e.g. \"W\" for Weekly, \"M\" for Monthly, \"3T\" for Trimestral, \"Q\" for Quarterly,\n",
    "        \"Y\" for Yearly, etc. for Dataframe.resample (see refs.).\n",
    "    percentiles : list\n",
    "        List of Returns of Percentiles returned by vs.Stats[0] dataframe (e.g. [.05, .25, .5, .75, .95]).\n",
    "    dist : list\n",
    "        Continuous Distributions to fit on datasets Xi\n",
    "    title : str\n",
    "        Title of the Box-plot\n",
    "    color : str\n",
    "        Color of the Box-plot.\n",
    "    Returns:\n",
    "    -------\n",
    "    describe : dataframe\n",
    "        Stats returns summary statistics (mean, std, min, max, percentiles, skewness and kurtosis) in a \n",
    "        markdown object callable as a dataframe by assigning a variable to the function in pos. [2].  \n",
    "    \"\"\"\n",
    "    \n",
    "    if  r == \"Simple\" :\n",
    "        Selection = (dataframe[Selection.index].pct_change()).iloc[1:, :].dropna(axis = 1)\n",
    "    if  r == \"Log\" :\n",
    "        Selection = np.log(dataframe[Selection.index]).diff().iloc[1:, :].dropna(axis = 1)\n",
    "    if r != \"Simple\" and r != \"Log\" :\n",
    "        print(\"Aborted: Please select a valid Return type: 'Simple' or 'Log'. Stats help command: help(vs.Stats)\")\n",
    "    \n",
    "    Selection.index = pd.to_datetime(Selection.index)\n",
    "    Selection_Mo_r = Selection.resample(P).agg(lambda x: x[-1])\n",
    "    Selection_Mo_r.plot(kind = \"box\", figsize = (22, 13), title = title, color = color, fontsize = 13)\n",
    "    \n",
    "    for i in range(0, len(Selection_Mo_r.columns)):\n",
    "        plt.text(x = i + 0.96 , y = Selection_Mo_r.iloc[:, i].mean() + .0075, s = str(\"$\\mu$ = +\") + str(round(Selection_Mo_r.iloc[:, i].mean(), 4)), fontsize = 6.5, fontweight = \"bold\", color = \"lightgreen\")\n",
    "        plt.text(x = i + 0.98 , y = Selection_Mo_r.iloc[:, i].max() + .010, s = str(\"+\") + str(round(Selection_Mo_r.iloc[:, i].max(), 3)), fontsize = 8.5, color = \"green\")\n",
    "        plt.text(x = i + 0.98 , y = Selection_Mo_r.iloc[:, i].min() - .015, s = str(round(Selection_Mo_r.iloc[:, i].min(), 3)), fontsize = 8.5, color = \"red\")\n",
    "\n",
    "    describe = Selection_Mo_r.describe(percentiles)\n",
    "    describe[\"mode\"] = Selection_Mo_r.mode().iloc[0, :]\n",
    "    describe[\"skewness\"] = st.skew(Selection_Mo_r)\n",
    "    describe[\"kurtosis\"] = st.kurtosis(Selection_Mo_r)\n",
    "    describe.replace(\"\\n\", \"\")\n",
    "\n",
    "    dist_fit = np.empty(len(Selection_Mo_r.columns), dtype=object)\n",
    "    \n",
    "    for i in range(0, len(Selection.columns)):\n",
    "        f = Fitter(pd.DataFrame(Selection_Mo_r.iloc[:, i]), distributions = dist, timeout=5)\n",
    "        f.fit()\n",
    "        params, AIC, BIC = [StringIO() for i in range(3)]\n",
    "        (print(f.get_best(), file=params)), (print(f.get_best(method=\"aic\"), file=AIC)), (print(f.get_best(method=\"bic\"), file=BIC))\n",
    "        params, AIC, BIC = [i.getvalue() for i in [params, AIC, BIC]]\n",
    "        dist_fit[i] = (params + AIC + BIC).replace(\"\\n\", \", \")\n",
    "    \n",
    "    plt.title(title, fontsize = 20)\n",
    "    plt.axhline(0, color = \"red\", lw = .5, linestyle = \"--\")\n",
    "    plt.axhspan(0, Selection_Mo_r.min().min(), facecolor = \"red\", alpha = 0.2) \n",
    "    plt.axhspan(0, Selection_Mo_r.max().max(), facecolor = \"green\", alpha = 0.2)\n",
    "\n",
    "    plt.xticks(rotation = 45)\n",
    "    for i, t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
    "        if (i % 2) != 0:\n",
    "            t.set_color(\"lightgreen\")\n",
    "        else:\n",
    "            t.set_color(\"white\")\n",
    "            \n",
    "    plt.yticks(np.arange(round(Selection_Mo_r.min().min(), 1), round(Selection_Mo_r.max().max(), 1), 0.05))\n",
    "    plt.grid(alpha = 0.5, linestyle = \"--\", color = \"grey\")\n",
    "    IPython.core.display.clear_output() \n",
    "    return describe, dist_fit, plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sortino25[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selection.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SP_Assets_r.loc[start:today][Sortino25[2].index]).pct_change().iloc[1:, :].dropna(axis = 1).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(SP_Assets_r.loc[start:today][Sortino25[2].index]).diff().iloc[1:, :].dropna(axis = 1).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_Assets_r.loc[start:today], Sortino25[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=([d for d in dir(st) if isinstance(getattr(st, d), getattr(st, \"rv_continuous\"))])[0:60]\n",
    "\n",
    "def ret(dataframe, selection, r):\n",
    "    if  r == \"Simple\" :\n",
    "        returns = (dataframe[selection.index]).pct_change().iloc[1:, :].dropna(axis = 1)\n",
    "    if  r == \"Log\" :\n",
    "        returns = np.log(dataframe[selection.index]).diff().iloc[1:, :].dropna(axis = 1)   \n",
    "    if r != \"Simple\" and r != \"Log\" :\n",
    "        print(\"Aborted: Please select a valid Return type: 'Simple' or 'Log'. selection_data help command: help(vs.selection_data)\")\n",
    "    \n",
    "    returns.index = pd.to_datetime(returns.index)\n",
    "    returns_Mo_r = returns.resample(\"M\").agg(lambda x: x[-1])\n",
    "    returns_Mo_r.plot(kind = \"box\", figsize = (22, 13), title = \"test\", color = \"yellow\", fontsize = 13)\n",
    "\n",
    "    return returns, returns_Mo_r.max()\n",
    "\n",
    "ret(SP_Assets_r.loc[start:today], Sortino25[2], \"Simple\")[1]\n",
    "\n",
    "\n",
    "#Selection.index = pd.to_datetime(Sortino25[2].index)\n",
    "# Selection_Mo_r = Selection.resample(P).agg(lambda x: x[-1])\n",
    "# Selection_Mo_r.plot(kind = \"box\", figsize = (22, 13), title = title, color = color, fontsize = 13)\n",
    "\n",
    "# for i in range(0, len(Selection_Mo_r.columns)):\n",
    "#     plt.text(x = i + 0.96 , y = Selection_Mo_r.iloc[:, i].mean() + .0075, s = str(\"$\\mu$ = +\") + str(round(Selection_Mo_r.iloc[:, i].mean(), 4)), fontsize = 6.5, fontweight = \"bold\", color = \"lightgreen\")\n",
    "#     plt.text(x = i + 0.98 , y = Selection_Mo_r.iloc[:, i].max() + .010, s = str(\"+\") + str(round(Selection_Mo_r.iloc[:, i].max(), 3)), fontsize = 8.5, color = \"green\")\n",
    "#     plt.text(x = i + 0.98 , y = Selection_Mo_r.iloc[:, i].min() - .015, s = str(round(Selection_Mo_r.iloc[:, i].min(), 3)), fontsize = 8.5, color = \"red\")\n",
    "\n",
    "# describe = Selection_Mo_r.describe(percentiles)\n",
    "# describe[\"mode\"] = Selection_Mo_r.mode().iloc[0, :]\n",
    "# describe[\"skewness\"] = st.skew(Selection_Mo_r)\n",
    "# describe[\"kurtosis\"] = st.kurtosis(Selection_Mo_r)\n",
    "# describe.replace(\"\\n\", \"\")\n",
    "\n",
    "# dist_fit = np.empty(len(Selection_Mo_r.columns), dtype=object)\n",
    "\n",
    "# for i in range(0, len(Selection.columns)):\n",
    "#     f = Fitter(pd.DataFrame(Selection_Mo_r.iloc[:, i]), distributions = dist, timeout=5)\n",
    "#     f.fit()\n",
    "#     params, AIC, BIC = [StringIO() for i in range(3)]\n",
    "#     (print(f.get_best(), file=params)), (print(f.get_best(method=\"aic\"), file=AIC)), (print(f.get_best(method=\"bic\"), file=BIC))\n",
    "#     params, AIC, BIC = [i.getvalue() for i in [params, AIC, BIC]]\n",
    "#     dist_fit[i] = (params + AIC + BIC).replace(\"\\n\", \", \")\n",
    "\n",
    "# plt.title(title, fontsize = 20)\n",
    "# plt.axhline(0, color = \"red\", lw = .5, linestyle = \"--\")\n",
    "# plt.axhspan(0, Selection_Mo_r.min().min(), facecolor = \"red\", alpha = 0.2) \n",
    "# plt.axhspan(0, Selection_Mo_r.max().max(), facecolor = \"green\", alpha = 0.2)\n",
    "\n",
    "# plt.xticks(rotation = 45)\n",
    "# for i, t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
    "#     if (i % 2) != 0:\n",
    "#         t.set_color(\"lightgreen\")\n",
    "#     else:\n",
    "#         t.set_color(\"white\")\n",
    "        \n",
    "# plt.yticks(np.arange(round(Selection_Mo_r.min().min(), 1), round(Selection_Mo_r.max().max(), 1), 0.05))\n",
    "# plt.grid(alpha = 0.5, linestyle = \"--\", color = \"grey\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'black'> \n",
    "\n",
    "$r_{Log}(X_i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selection = np.log(dataframe[Selection.index]).diff().iloc[1:, :].dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats(dataframe, Selection, r, P, percentiles, dist, title, color):\n",
    "describe_Wk = Stats(SP_Assets_r.loc[start:today], Sortino25[2], \"Log\", \"W\", [.025, .25, .5, .75, .95], dist, \n",
    "                    \"$S&P$ 500 $r_{Log}(X_i)$ Selection Weekly Resampling from\" + str(start) + \"to\" + str(today), \"lightyellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_Wk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_Mo = vs.Stats(SP_Assets_r.loc[\"2020-03-02\":today], Sortino25[2], P[1][0],\n",
    "                  \"$X_i$ Selection Resamplings from $S&P$ 500 on a \" + str(P[1][1]) + \" basis from \", \"2020-03-02\", today,\n",
    "                  [.025, .25, .5, .75, .95], dist, color=color[1])\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_Mo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_Qt = vs.Stats(SP_Assets_r.loc[\"2020-03-02\":today], Sortino25[2], P[2][0],\n",
    "                  \"$X_i$ Selection Resamplings from $S&P$ 500 on a \" + str(P[2][1]) + \" basis from \", \"2020-03-02\", today,\n",
    "                  [.025, .25, .5, .75, .95], dist, color=color[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_Qt[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'black'> Estimators Parameters:\n",
    "$f(X_i)$ and $AIC$ $\\&$ $BIC$: <br>\n",
    "\n",
    "Distributions and parameters that best estimate $f(X_i)$ are obtained from $104$ distribution classes and instances for continuous random variables in `Fitter` module  *(see refs.)*. <br>\n",
    "\n",
    "The *$AIC$ Akaike $\\&$ $BIC$ Bayesian Information Criterion* models are estimators of *relative quality* of predictions in the *Log-Likelihood* for fitted distributions.<br>\n",
    "Minimum relative values for $AIC$ and $BIC$ are usually preferred and in this case, they are obtained to model $X_i$ resampled data on $W, M$   $\\&$ $Q$ periods $P$.<br>\n",
    "Criterion's goodness of fit is inversely related so they tend to be used together to avoid under/over fitting and they are defined as follows:\n",
    "+ $AIC = 2k - 2ln(\\hat{L})$<br>\n",
    "+ $BIC = kln(n) - 2ln(\\hat{L})$<br>\n",
    "\n",
    "*where:*<br>\n",
    "\n",
    " $k$ = Params. in  model.<br>\n",
    " $n$ = No of observations.<br>\n",
    " $\\hat{L}$ = $Likelihood_{f_{max.}}$.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fit=pd.DataFrame([describe_Wk[1], describe_Mo[1], describe_Qt[1]]).T\n",
    "dist_fit_format = fn.format_table(dist_fit, Sortino25[2])\n",
    "dist_fit_format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= 'blue'> \n",
    "\n",
    "### 3. Descriptive and Prescriptive Analytics for $X_P$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'blue'> <br>\n",
    "3.1 $X_P$ Optimizations Models <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:gray'> *Equal weighted datasets are omitted from the analysis for simplicity purposes.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "If we have $n$ *unequally* weighted datasets $X_i=1,2,.., n$, to model $X_P$ we need $\\mu_P$ $\\&$ $\\sigma_P$.<br>\n",
    "\n",
    "And their weighted average is concluded:<br>\n",
    "\n",
    "$$\\mu_{P} = \\frac{\\sum_{i=1}^{n} w_{i} \\mu_{{X_{i}}}}{\\sum_{i=1}^{n} w_{i}}$$ \n",
    "\n",
    "If $$\\sum_{i=1}^{n} w_{i} = 1$$ then: <br>\n",
    "\n",
    "$$\\mu_{P} = \\sum_{i=1}^{n} w_{i} \\mu_{{X_{i}}}$$ \n",
    "\n",
    "For the variance $\\sigma^2_P$ we need to express $X_{i,j}$ as a matrix from the selection in $S\\&P500$ *(A-Z)* quotes where ${\\sigma_{i} \\sigma_{j}}$ is the product of $X_{i,j}$ units of risk:<br>\n",
    "\n",
    "$$\\sigma_{i,j} = \\left[\\begin{array}{cccc}\\sigma_{1} & \\sigma_{1,2} & \\cdots & \\sigma_{1,500} \\\\ \\sigma_{2,1} & \\sigma_{2} & \\cdots & \\sigma_{2,500} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\sigma_{500,1} & \\cdots & \\cdots & \\sigma_{500}\\end{array}\\right]$$\n",
    "\n",
    "We also need $X_{i,j}$ correlation coefficients $\\rho_{i j}$ = $\\frac{Cov(X_i, X_{j})}{\\sigma_{i} \\sigma_{j}}$ or units of risk in $X_{i,j}$ that are not shared in their fluctuations directional relationship.<br>\n",
    "\n",
    "Expressed and substituted as:\n",
    "\n",
    "$$\\sigma^2_P=\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i}w_{j}\\sigma_{i}\\sigma_{j}\\rho_{ij}$$ \n",
    "\n",
    "$$\\sigma^2_P = \\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i}w_{j}Cov(X_i, X_j)$$\n",
    "\n",
    "A product of matrices $\\times$ vectors:<br>\n",
    "\n",
    "$$\\sigma^2_{P} = \\vec{w}^T \\times Cov_{i,j} \\times \\vec{w}$$\n",
    "\n",
    "Reduced and expressed as the following in its expanded form:<br> \n",
    "\n",
    "$$\\sigma^2_{P} = {\\left[\\begin{array}{cccc}w_{1} & w_{2} & \\cdots & w_{n}\\end{array}\\right] \\cdot \\left[\\begin{array}{cccc}1 & \\rho_{1,2} & \\cdots & \\rho_{1,n} \\\\ \\rho_{2,1} & 1 & \\cdots & \\rho_{2,n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{n,1} & \\cdots & \\cdots & 1\\end{array}\\right] \\cdot \\left[\\begin{array}{cccc}w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{n}\\end{array}\\right]}$$\n",
    "\n",
    "Now, the slope can be obtained from $X_{P}$ and $X_{S\\&P500}$ which is expressed as:<br>\n",
    "\n",
    "$\\beta = \\frac{Cov(r_P,r_{S\\&P500})}{Var(r_{S\\&P500})}$\n",
    "\n",
    "To compute some metrics that include units of sensitivities the following are considered:<br>\n",
    "\n",
    "+ $R_{Treynor} = \\frac{Var(r_{S\\&P500})(\\mu_P - {rf})}{Cov(r_P,r_{S\\&P500})}$<br>\n",
    "\n",
    "or the *slope* per unit of $P$ excess returns over the risk-free.\n",
    "\n",
    "+ $R_{Jensen}({r_P, r_{t_{S\\&P500}}}) = (\\mu_P - {rf}) - \\frac{Cov(r_P,r_{t_{S\\&P500}})}{Var(r_{t_{S\\&P500}})}(\\mu_{t_{S\\&P500}} - {rf})$<br>\n",
    "\n",
    "or excess returns of $P$ over the risk free minus the *slope* times $P$ excess returns of a benchmark over the risk-free."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, the slope can be obtained from $X_{P}$ and $X_{S\\&P500}$ which is expressed as:<br>\n",
    "\n",
    "$\\beta = \\frac{Cov(r_P,r_{S\\&P500})}{Var(r_{S\\&P500})}$\n",
    "\n",
    "To compute some metrics that include units of sensitivities the following are considered:<br>\n",
    "\n",
    "+ $R_{Treynor} = \\frac{Var(r_{S\\&P500})(\\mu_P - {rf})}{Cov(r_P,r_{S\\&P500})}$<br>\n",
    "\n",
    "or the *slope* per unit of $P$ excess returns over the risk-free.\n",
    "\n",
    "+ $R_{Jensen}({r_P, r_{t_{S\\&P500}}}) = (\\mu_P - {rf}) - \\frac{Cov(r_P,r_{t_{S\\&P500}})}{Var(r_{t_{S\\&P500}})}(\\mu_{t_{S\\&P500}} - {rf})$<br>\n",
    "\n",
    "or excess returns of $P$ over the risk free minus the *slope* times $P$ excess returns of a benchmark over the risk-free.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:black'>\n",
    "\n",
    "Optimizations $\\forall w_i$ are made with `Scipy` and validated with `Numpy` from parameters $X_i \\rightarrow X_P$ for:<br><br>\n",
    "+ $R_{Treynor_{Arg_{max}}}$\n",
    "+ $R_{Sharpe_{Arg_{max}}}$\n",
    "+ $R_{Sortino_{Arg_{max}}}$\n",
    "+ $\\sigma^2_{P_{Arg_{min}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimizer(Assets, index, rf, title):\n",
    "    Asset_ret = (Assets.pct_change()).iloc[1:, :].dropna(axis = 1)\n",
    "    index_ret = index.pct_change().iloc[1:, :].dropna(axis = 1)\n",
    "    index_ret = index_ret[index_ret.index.isin(Asset_ret.index)]\n",
    "\n",
    "    mean_ret = Asset_ret.mean() * 252\n",
    "    cov = Asset_ret.cov() * 252\n",
    "\n",
    "    N = len(mean_ret)\n",
    "    w0 = np.ones(N) / N\n",
    "    bnds = ((0, None), ) * N\n",
    "    cons = {\"type\" : \"eq\", \"fun\" : lambda weights : weights.sum() - 1}\n",
    "\n",
    "    def Max_Sharpe(weights, Asset_ret, rf, cov):\n",
    "        rp = np.dot(weights.T, Asset_ret)\n",
    "        sp = np.sqrt(np.dot(weights.T, np.dot(cov, weights)))\n",
    "        RS = (rp - rf) / sp\n",
    "        return -(np.divide(np.subtract(rp, rf), sp))\n",
    "    \n",
    "    def Min_Var(weights, cov):\n",
    "        return np.dot(weights.T, np.dot(cov, weights)) \n",
    "    \n",
    "    def Min_Traynor(weights, Asset_ret, rf, cov):\n",
    "        #(rp - rf) / Beta\n",
    "        rp = np.dot(weights.T, Asset_ret)\n",
    "        varp = np.dot(weights.T, np.dot(cov, weights))\n",
    "        cov\n",
    "        RT = (rp - rf) / sp\n",
    "        return -(np.divide(np.subtract(rp, rf), sp))\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    opt_EMV = optimize.minimize(Max_Sharpe, w0, (mean_ret, rf, cov), 'SLSQP', bounds = bnds,\n",
    "                                constraints = cons, options={\"tol\": 1e-10})\n",
    "    \n",
    "    W_EMV = pd.DataFrame(np.round(opt_EMV.x.reshape(1, N), 4), columns = Asset_ret.columns, index = [\"Weights\"])\n",
    "    W_EMV[W_EMV <= 0.0] = np.nan\n",
    "    W_EMV.dropna(axis = 1, inplace = True)\n",
    "\n",
    "    RAssets = Asset_ret[Asset_ret.columns[Asset_ret.columns.isin(W_EMV.columns)]]\n",
    "    # MuAssets = mean_ret[mean_ret.index.isin(W_EMV.columns)]\n",
    "    R_EMV = pd.DataFrame((RAssets*W_EMV.values).sum(axis = 1), columns = [\"$r_{Sharpe_{Arg_{max}}}$\"])\n",
    "    index_ret.rename(columns={index_ret.columns[0]: \"$r_{mkt}$\" }, inplace=True)\n",
    "    R_EMV.insert(1, index_ret.columns[0], index_ret.values)\n",
    "\n",
    "    Muopt_EMV = np.dot(opt_EMV.x.T, mean_ret) \n",
    "    Sopt_EMV = np.sqrt(np.dot(opt_EMV.x.T, np.dot(cov, opt_EMV.x)))\n",
    "    Beta_EMV = np.divide((np.cov(R_EMV.iloc[0], R_EMV.iloc[1])[0][1]), R_EMV.iloc[1].var())\n",
    "    SR_EMV = (Muopt_EMV - rf) / Sopt_EMV\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    opt_MinVar = optimize.minimize(Min_Var, np.ones(N) / N, (cov,), 'SLSQP', bounds = bnds,\n",
    "                                   constraints = cons, options={\"tol\": 1e-10})\n",
    "\n",
    "    W_MinVar = pd.DataFrame(np.round(opt_MinVar.x.reshape(1, N), 4), columns = Asset_ret.columns, index = [\"Weights\"])\n",
    "    W_MinVar[W_MinVar <= 0.0] = np.nan\n",
    "    W_MinVar.dropna(axis = 1, inplace = True)\n",
    "\n",
    "    RAssets_MinVar = Asset_ret[Asset_ret.columns[Asset_ret.columns.isin(W_MinVar.columns)]]\n",
    "    R_MinVar = pd.DataFrame((RAssets_MinVar*W_MinVar.values).sum(axis = 1), columns = [\"$r_{Var_{Arg_{min}}}$\"])\n",
    "    R_EMV.insert(2, R_MinVar.columns[0], R_MinVar.values)\n",
    "\n",
    "    Muopt_MinVar = np.dot(opt_MinVar.x.T, mean_ret) \n",
    "    Sopt_MinVar = np.sqrt(np.dot(opt_MinVar.x.T, np.dot(cov, opt_MinVar.x)))\n",
    "    Beta_MinVar = np.divide((np.cov(R_EMV.iloc[2], R_EMV.iloc[1])[0][1]), R_EMV.iloc[1].var())\n",
    "    SR_MinVar = (Muopt_MinVar - rf) / Sopt_MinVar \n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #opt_Traynor = \n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    Mu, Sigma, Beta, SR = [Muopt_EMV, Muopt_MinVar], [Sopt_EMV, Sopt_MinVar], [Beta_EMV, Beta_MinVar], [SR_EMV, SR_MinVar]\n",
    "    index = [\"$r_{P{Sharpe_{Arg_{max}}}}$\", \"$r_{Var_{Arg_{min}}}$\"]\n",
    "    Popt = [pd.DataFrame({\"$\\mu_P$\" : Mu[i], \"$\\sigma_P$\" : Sigma[i], \"$\\Beta_{P}$\": Beta[i], \"$r_{Sharpe_{Arg_{max}}}$\" : SR[i]},\n",
    "                          index = [index[i]]) for i in range(0, len(Mu))]\n",
    "    \n",
    "    Popt[0].index.name = title\n",
    "    Popt[1].index.name = title\n",
    "    R_EMV = R_EMV[[R_EMV.columns[1], R_EMV.columns[2], R_EMV.columns[0]]]\n",
    "    #Get the cumulative returns with cumsum for rmkt, rEMV and rMinVar\n",
    "    accum = R_EMV.cumsum()\n",
    "\n",
    "    Argmax = [d.Markdown(tabulate(Popt[i], headers = \"keys\", tablefmt = \"pipe\")) for i in range(0, len(Popt))]\n",
    "    R_EMV = d.Markdown(tabulate(R_EMV, headers = \"keys\", tablefmt = \"pipe\"))\n",
    "    \n",
    "    return Argmax, R_EMV, accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_md = \"$S\\&P500_{{20_{03}-23_{05}}}$\"\n",
    "Argmax, R_EMV, accum = vs.Optimizer(SP_Assets_r.loc[\"2020-03-02\":today], SP_r.loc[\"2020-03-02\":today], 0.0169, bench_md)\n",
    "\n",
    "Port = display(Argmax[0], Argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.Markdown(tabulate(accum.dropna()[0:10], headers = \"keys\", tablefmt = \"pipe\")) \n",
    "#Non sliced: d.Markdown(tabulate(accum.diff().dropna()[], headers = \"keys\", tablefmt = \"pipe\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d.display(d.Markdown(tabulate(accum[0:10], headers = \"keys\", tablefmt = \"pipe\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d.display(d.Markdown(tabulate(accum[0:10], headers = \"keys\", tablefmt = \"pipe\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.Accum_ts(accum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color= 'blue'> Metrics: <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Confusion Matrix: <br> $\\begin{bmatrix} TP & FP \\\\ FN & TN \\end{bmatrix}$\n",
    "\n",
    "Metrics:\n",
    "\n",
    "- Accuracy: $\\frac{TP + TN}{TP + TN + FP + FN}$ or the ability of the classifier to find + and - samples.\n",
    "\n",
    "- Precision: $\\frac{TP}{TP + FP}$ or the ability of the classifier not to label + samples as -.\n",
    "\n",
    "- Recall: $\\frac{TP}{TP + FN}$ or the ability of the classifier to find all + samples.\n",
    "\n",
    "- F1 Score: $2 * \\frac{Precision * Recall}{Precision + Recall}$ or Precision and Recall equilibrated score through the harmonic mean.    \n",
    "\n",
    "- ROC AUC: $\\frac{TPR}{FPR}$ or the ability of the classifier to find + samples and not - samples. Where a bigger number denotes a better model.<br><br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:lightyellow'> ~ *Past performance is not a guarantee of future results, the stock market tends to be irrational.* <font>\n",
    "\n",
    "Note: <br>\n",
    "Do not consider the results and/or its proceedures as an investment advice or recommendation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
